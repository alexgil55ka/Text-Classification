{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Text Classification - w/Pytorch",
      "provenance": [],
      "collapsed_sections": [
        "ZB9YrNk9959h",
        "zjjHxmHw-CnD",
        "pef6EqLy-TvO",
        "5qVnnJ-R-aWc",
        "KXVbeuRkqnqf"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "bcc00ba939b140898eb19c02a779fd8e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_721f48624ef14cf2bb3304e0ba3a1dc1",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_2a6ff6f11e494677a51de691c42e0987",
              "IPY_MODEL_2f49a14a44224f0895545cdd5ac647d5"
            ]
          }
        },
        "721f48624ef14cf2bb3304e0ba3a1dc1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2a6ff6f11e494677a51de691c42e0987": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_acf2de5a1e384a1fb45f6eb69b1ac935",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 480,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 480,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4e9ab806cf9a48c8a15f2250c6024d0e"
          }
        },
        "2f49a14a44224f0895545cdd5ac647d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_c0b500dffffe4c0e89d135a90eb13907",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 480/480 [00:02&lt;00:00, 200B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a04a15545bb1434d80f3ed0aeb883257"
          }
        },
        "acf2de5a1e384a1fb45f6eb69b1ac935": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4e9ab806cf9a48c8a15f2250c6024d0e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c0b500dffffe4c0e89d135a90eb13907": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a04a15545bb1434d80f3ed0aeb883257": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a8eb5043851343f8b79808f8802e5c91": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_6c93a3635c7f437dbdbbbffcdcf8ac8a",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_5e13337672e34331851f9c7004df895d",
              "IPY_MODEL_98a9d6bc03ab492290f55934ebc2d403"
            ]
          }
        },
        "6c93a3635c7f437dbdbbbffcdcf8ac8a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5e13337672e34331851f9c7004df895d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_c9cea9b553dc429ba0b6b514181bb633",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 898823,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 898823,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1aa09c2533a04f8c9fb3b443d966de7c"
          }
        },
        "98a9d6bc03ab492290f55934ebc2d403": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_2710798b6d8e4a538b87cadf85c04e63",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 899k/899k [00:01&lt;00:00, 744kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9656b80ea6934c4d84fc412f34b09c2f"
          }
        },
        "c9cea9b553dc429ba0b6b514181bb633": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "1aa09c2533a04f8c9fb3b443d966de7c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2710798b6d8e4a538b87cadf85c04e63": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "9656b80ea6934c4d84fc412f34b09c2f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e90256d96c7948468493b1be05014f89": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_8c6a3e1d27074f38a70dfe384ebc8386",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_9cc4363dcdfe4fb595cd1db3abf0ae56",
              "IPY_MODEL_cbdf1b62184146ff977974324e5f13aa"
            ]
          }
        },
        "8c6a3e1d27074f38a70dfe384ebc8386": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9cc4363dcdfe4fb595cd1db3abf0ae56": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_835b64fd8d4643328443447a75a0ed9c",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 456318,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 456318,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_56f291dec63d478c936324438a3a3926"
          }
        },
        "cbdf1b62184146ff977974324e5f13aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_2978d465aca5416183441bdf5e11bc49",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 456k/456k [00:00&lt;00:00, 1.14MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_39375eadd45547c4993c90913027fb9c"
          }
        },
        "835b64fd8d4643328443447a75a0ed9c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "56f291dec63d478c936324438a3a3926": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2978d465aca5416183441bdf5e11bc49": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "39375eadd45547c4993c90913027fb9c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9ec680952dab4979b4f349d5ee8a19de": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_241da0c967e649bca9af94d3bdcc0faf",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_054c658bb2e14e63969a380b30bdf286",
              "IPY_MODEL_8226e1675b024ad48b7d1932a0895354"
            ]
          }
        },
        "241da0c967e649bca9af94d3bdcc0faf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "054c658bb2e14e63969a380b30bdf286": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_12f62c18b14f497bb439100f8b2b1837",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 331070498,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 331070498,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2d1e26a4d2084ddca0ac3fb0afec67e6"
          }
        },
        "8226e1675b024ad48b7d1932a0895354": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_19cc0fb57f334854bc51096324a8cad2",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 331M/331M [00:46&lt;00:00, 7.09MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_eb68d93009c04b2dbdc21a096c9702b3"
          }
        },
        "12f62c18b14f497bb439100f8b2b1837": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2d1e26a4d2084ddca0ac3fb0afec67e6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "19cc0fb57f334854bc51096324a8cad2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "eb68d93009c04b2dbdc21a096c9702b3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZB9YrNk9959h"
      },
      "source": [
        "## Installing dependencies"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4TXUvxCeYx_z",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "abde8dfa-4c34-4fc2-f431-13f27c176d3d"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VMxepEUoe6tQ",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 626
        },
        "outputId": "05304dff-dafc-4981-cc11-7fb8bb662958"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ae/05/c8c55b600308dc04e95100dc8ad8a244dd800fe75dfafcf1d6348c6f6209/transformers-3.1.0-py3-none-any.whl (884kB)\n",
            "\r\u001b[K     |▍                               | 10kB 19.5MB/s eta 0:00:01\r\u001b[K     |▊                               | 20kB 6.5MB/s eta 0:00:01\r\u001b[K     |█▏                              | 30kB 7.7MB/s eta 0:00:01\r\u001b[K     |█▌                              | 40kB 7.7MB/s eta 0:00:01\r\u001b[K     |█▉                              | 51kB 7.0MB/s eta 0:00:01\r\u001b[K     |██▎                             | 61kB 7.5MB/s eta 0:00:01\r\u001b[K     |██▋                             | 71kB 7.9MB/s eta 0:00:01\r\u001b[K     |███                             | 81kB 8.4MB/s eta 0:00:01\r\u001b[K     |███▍                            | 92kB 7.9MB/s eta 0:00:01\r\u001b[K     |███▊                            | 102kB 8.1MB/s eta 0:00:01\r\u001b[K     |████                            | 112kB 8.1MB/s eta 0:00:01\r\u001b[K     |████▌                           | 122kB 8.1MB/s eta 0:00:01\r\u001b[K     |████▉                           | 133kB 8.1MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 143kB 8.1MB/s eta 0:00:01\r\u001b[K     |█████▋                          | 153kB 8.1MB/s eta 0:00:01\r\u001b[K     |██████                          | 163kB 8.1MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 174kB 8.1MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 184kB 8.1MB/s eta 0:00:01\r\u001b[K     |███████                         | 194kB 8.1MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 204kB 8.1MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 215kB 8.1MB/s eta 0:00:01\r\u001b[K     |████████▏                       | 225kB 8.1MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 235kB 8.1MB/s eta 0:00:01\r\u001b[K     |█████████                       | 245kB 8.1MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 256kB 8.1MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 266kB 8.1MB/s eta 0:00:01\r\u001b[K     |██████████                      | 276kB 8.1MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 286kB 8.1MB/s eta 0:00:01\r\u001b[K     |██████████▊                     | 296kB 8.1MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 307kB 8.1MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 317kB 8.1MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 327kB 8.1MB/s eta 0:00:01\r\u001b[K     |████████████▎                   | 337kB 8.1MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 348kB 8.1MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 358kB 8.1MB/s eta 0:00:01\r\u001b[K     |█████████████▍                  | 368kB 8.1MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 378kB 8.1MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 389kB 8.1MB/s eta 0:00:01\r\u001b[K     |██████████████▌                 | 399kB 8.1MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 409kB 8.1MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 419kB 8.1MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 430kB 8.1MB/s eta 0:00:01\r\u001b[K     |████████████████                | 440kB 8.1MB/s eta 0:00:01\r\u001b[K     |████████████████▎               | 450kB 8.1MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 460kB 8.1MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 471kB 8.1MB/s eta 0:00:01\r\u001b[K     |█████████████████▍              | 481kB 8.1MB/s eta 0:00:01\r\u001b[K     |█████████████████▉              | 491kB 8.1MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 501kB 8.1MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 512kB 8.1MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 522kB 8.1MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 532kB 8.1MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 542kB 8.1MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 552kB 8.1MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 563kB 8.1MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 573kB 8.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 583kB 8.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████▌          | 593kB 8.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 604kB 8.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 614kB 8.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████▋         | 624kB 8.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 634kB 8.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 645kB 8.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 655kB 8.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 665kB 8.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 675kB 8.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████▉       | 686kB 8.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 696kB 8.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▋      | 706kB 8.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 716kB 8.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▎     | 727kB 8.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 737kB 8.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 747kB 8.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 757kB 8.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 768kB 8.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 778kB 8.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 788kB 8.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████   | 798kB 8.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▎  | 808kB 8.1MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 819kB 8.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 829kB 8.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 839kB 8.1MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▊ | 849kB 8.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 860kB 8.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 870kB 8.1MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▉| 880kB 8.1MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 890kB 8.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n",
            "Collecting tokenizers==0.8.1.rc2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/80/83/8b9fccb9e48eeb575ee19179e2bdde0ee9a1904f97de5f02d19016b8804f/tokenizers-0.8.1rc2-cp36-cp36m-manylinux1_x86_64.whl (3.0MB)\n",
            "\u001b[K     |████████████████████████████████| 3.0MB 31.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 50.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n",
            "Collecting sentencepiece!=0.1.92\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/a4/d0a884c4300004a78cca907a6ff9a5e9fe4f090f5d95ab341c53d28cbc58/sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 43.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (1.15.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.16.0)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.6.20)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893257 sha256=a330f4574d8f6f63e19672663ed05b47317acf91599ca1ab2dab2022be3eebbc\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: tokenizers, sacremoses, sentencepiece, transformers\n",
            "Successfully installed sacremoses-0.0.43 sentencepiece-0.1.91 tokenizers-0.8.1rc2 transformers-3.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zjjHxmHw-CnD"
      },
      "source": [
        "## Importing modules"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lg5bB6ubeRe3"
      },
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, AdamW\n",
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler, TensorDataset\n",
        "import tensorflow as tf\n",
        "import torch\n",
        "import pandas as pd\n",
        "\n",
        "import random\n",
        "import numpy as np\n",
        "from sklearn.metrics import classification_report, f1_score\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "from tensorflow import summary\n",
        "import time\n",
        "import datetime\n",
        "%load_ext tensorboard"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0i8RJV1TmAqe"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "507M9koaZS1m",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b9dcd34c-4e85-4d26-eb7c-1e09a10c8eb5"
      },
      "source": [
        "# Getting the GPU device name\n",
        "device_name = tf.test.gpu_device_name()\n",
        "\n",
        "if device_name == '/device:GPU:0':\n",
        "  print('Found GPU at: {}'.format(device_name))\n",
        "else:\n",
        "  raise SystemError('GPU device not found')\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cKSuO8pzbR8k",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "65e2308c-c591-4cf2-d923-f598d519c4d0"
      },
      "source": [
        "if torch.cuda.is_available():\n",
        "  device = torch.device(\"cuda\")\n",
        "\n",
        "  print(\"There are %d GPU(s) available\" % torch.cuda.device_count())\n",
        "\n",
        "  print(\"We will use the GPU:\", torch.cuda.get_device_name(0))\n",
        "else:\n",
        "  print(\"No GPU available, using CPU\")\n",
        "  device = torch.device('cpu')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 1 GPU(s) available\n",
            "We will use the GPU: Tesla V100-SXM2-16GB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oPISt4XjdIHt"
      },
      "source": [
        "# Reading data\n",
        "train = pd.read_csv('/content/drive/My Drive/SST-2/train.tsv', sep='\\t')\n",
        "dev = pd.read_csv('/content/drive/My Drive/SST-2/dev.tsv', sep='\\t')\n",
        "test = pd.read_csv('/content/drive/My Drive/SST-2/test.tsv', sep='\\t')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pef6EqLy-TvO"
      },
      "source": [
        "## Pre-processing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bfnva60yYVAs",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 165,
          "referenced_widgets": [
            "bcc00ba939b140898eb19c02a779fd8e",
            "721f48624ef14cf2bb3304e0ba3a1dc1",
            "2a6ff6f11e494677a51de691c42e0987",
            "2f49a14a44224f0895545cdd5ac647d5",
            "acf2de5a1e384a1fb45f6eb69b1ac935",
            "4e9ab806cf9a48c8a15f2250c6024d0e",
            "c0b500dffffe4c0e89d135a90eb13907",
            "a04a15545bb1434d80f3ed0aeb883257",
            "a8eb5043851343f8b79808f8802e5c91",
            "6c93a3635c7f437dbdbbbffcdcf8ac8a",
            "5e13337672e34331851f9c7004df895d",
            "98a9d6bc03ab492290f55934ebc2d403",
            "c9cea9b553dc429ba0b6b514181bb633",
            "1aa09c2533a04f8c9fb3b443d966de7c",
            "2710798b6d8e4a538b87cadf85c04e63",
            "9656b80ea6934c4d84fc412f34b09c2f",
            "e90256d96c7948468493b1be05014f89",
            "8c6a3e1d27074f38a70dfe384ebc8386",
            "9cc4363dcdfe4fb595cd1db3abf0ae56",
            "cbdf1b62184146ff977974324e5f13aa",
            "835b64fd8d4643328443447a75a0ed9c",
            "56f291dec63d478c936324438a3a3926",
            "2978d465aca5416183441bdf5e11bc49",
            "39375eadd45547c4993c90913027fb9c"
          ]
        },
        "outputId": "869741e7-fb2b-4754-cc09-9916627d9a4a"
      },
      "source": [
        "# Tokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"distilroberta-base\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bcc00ba939b140898eb19c02a779fd8e",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=480.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a8eb5043851343f8b79808f8802e5c91",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=898823.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e90256d96c7948468493b1be05014f89",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=456318.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sDfLpQW4duxr"
      },
      "source": [
        "# Pre-processing\n",
        "def process(df, batch, method):\n",
        "\n",
        "  if method == 'train':\n",
        "    \n",
        "    # Getting a list of sentences and their labels\n",
        "    sentences = df.sentence.values\n",
        "    labels = df.label.values\n",
        "\n",
        "  else:\n",
        "    sentences = df.sentence.values\n",
        "\n",
        "  # Tokenizing\n",
        "  input_ids = []\n",
        "  attention_masks = []\n",
        "  token_type_ids = []\n",
        "\n",
        "  for sent in sentences:\n",
        "    encoded_dict = tokenizer.encode_plus(sent,\n",
        "                                         add_special_tokens=True, \n",
        "                                         max_length = 128,  \n",
        "                                         truncation = True,\n",
        "                                         padding = 'max_length', \n",
        "                                         return_attention_mask = True,\n",
        "                                         return_token_type_ids = True,\n",
        "                                         return_tensors = 'pt')\n",
        "    \n",
        "    input_ids.append(encoded_dict['input_ids'])\n",
        "    attention_masks.append(encoded_dict['attention_mask'])\n",
        "    token_type_ids.append(encoded_dict['token_type_ids'])\n",
        "  \n",
        "  input_ids = torch.cat(input_ids, dim=0)\n",
        "  attention_masks = torch.cat(attention_masks, dim=0)\n",
        "  token_types_ids = torch.cat(token_type_ids, dim=0)\n",
        "  if method == 'train':\n",
        "    labels = torch.tensor(labels)\n",
        "    \n",
        "    dataset = TensorDataset(input_ids, attention_masks, token_types_ids, labels)\n",
        "\n",
        "  else:\n",
        "    dataset = TensorDataset(input_ids, attention_masks, token_types_ids)\n",
        "\n",
        "  dataloader = DataLoader(dataset,\n",
        "                          sampler = RandomSampler(dataset),\n",
        "                          batch_size = batch)\n",
        "  \n",
        "  return dataloader"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YJpMIVeOQREB"
      },
      "source": [
        "def do_prediction(model, dataloader, device):\n",
        "  \"\"\"\n",
        "  Make Prediction\n",
        "  \"\"\"\n",
        "\n",
        "  preds, true_labels = [], []\n",
        "\n",
        "  model.eval()\n",
        "  for batch in dataloader:\n",
        "    # Add batch to GPU\n",
        "    batch = tuple(t.to(device) for t in batch)\n",
        "    # Unpack the inputs from our dataloader\n",
        "    b_input_ids, b_input_mask, b_token_type_ids = batch\n",
        "\n",
        "    # Telling the model not to compute or store gradients, \n",
        "    # saving memory and speeding up prediction\n",
        "    with torch.no_grad():\n",
        "      # Forward pass, calculate logit predictions\n",
        "      outputs = model(b_input_ids,\n",
        "                      token_type_ids=b_token_type_ids,\n",
        "                      attention_mask=b_input_mask)\n",
        "      \n",
        "      logits = outputs[0]\n",
        "\n",
        "      # Move logits and labels to CPU\n",
        "      logits = logits.detach().cpu().numpy()\n",
        "      #label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "      # Store predictions and true labels\n",
        "      preds.append(logits)\n",
        "      #true_labels.append(label_ids)\n",
        "\n",
        "  # Combine the results across all batches\n",
        "  flat_preds = np.concatenate(preds, axis=0)\n",
        "\n",
        "  # For each sample, pick the label with higher score\n",
        "  flat_preds = np.argmax(flat_preds, axis=1)\n",
        "\n",
        "  # Combine the correct labels for each batch into a single list\n",
        " # flat_true_labels = np.concatenate(true_labels, axis=0)\n",
        "\n",
        "  return pd.DataFrame({'predictions':flat_preds.tolist()})\n",
        "  \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5qVnnJ-R-aWc"
      },
      "source": [
        "## Model Building"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BcHbbvHNrbpn"
      },
      "source": [
        "train_dataloader = process(train, 32, 'train')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZV5LESvx7WwF"
      },
      "source": [
        "dev_dataloader = process(dev, 32, 'train')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mJyeDLelsisC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "9ec680952dab4979b4f349d5ee8a19de",
            "241da0c967e649bca9af94d3bdcc0faf",
            "054c658bb2e14e63969a380b30bdf286",
            "8226e1675b024ad48b7d1932a0895354",
            "12f62c18b14f497bb439100f8b2b1837",
            "2d1e26a4d2084ddca0ac3fb0afec67e6",
            "19cc0fb57f334854bc51096324a8cad2",
            "eb68d93009c04b2dbdc21a096c9702b3"
          ]
        },
        "outputId": "5a35b2a0-a32c-4b05-c6b6-0c51ca59decd"
      },
      "source": [
        "model = AutoModelForSequenceClassification.from_pretrained(\"distilroberta-base\")\n",
        "model.cuda()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9ec680952dab4979b4f349d5ee8a19de",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=331070498.0, style=ProgressStyle(descri…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at distilroberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight']\n",
            "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at distilroberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RobertaForSequenceClassification(\n",
              "  (roberta): RobertaModel(\n",
              "    (embeddings): RobertaEmbeddings(\n",
              "      (word_embeddings): Embedding(50265, 768, padding_idx=1)\n",
              "      (position_embeddings): Embedding(514, 768, padding_idx=1)\n",
              "      (token_type_embeddings): Embedding(1, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (classifier): RobertaClassificationHead(\n",
              "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "    (out_proj): Linear(in_features=768, out_features=2, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rRjSuXcObBIz"
      },
      "source": [
        "optimizer = AdamW(model.parameters(),\n",
        "                  lr = 2e-5,\n",
        "                  eps = 1e-8)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aTB1LaWwb24a"
      },
      "source": [
        "epochs = 4\n",
        "\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "warmup_steps = total_steps * 0.01\n",
        "\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
        "                                            num_warmup_steps = warmup_steps,\n",
        "                                            num_training_steps = total_steps)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1mTA_ZzJcV-Z"
      },
      "source": [
        "def flat_accuracy(preds, labels):\n",
        "  pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "  labels_flat = labels.flatten()\n",
        "\n",
        "  return np.sum(pred_flat == labels_flat) / len(labels_flat)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D4Xc5NOKXAWm"
      },
      "source": [
        "def format_time(elapse):\n",
        "  \"\"\"\n",
        "  Get time delta\n",
        "  \"\"\"\n",
        "  elapse_rounded = int(round(elapse))\n",
        "  return str(datetime.timedelta(seconds=elapse_rounded))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CyRPFszKcjpT",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "f7a825dd-4aff-41a8-9130-0c08980f8254"
      },
      "source": [
        "seed_val = 42\n",
        "\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "\n",
        "training_stats = []\n",
        "\n",
        "total_t0 = time.time()\n",
        "# For each epoch...\n",
        "for epoch_i in range(0, epochs):\n",
        "    \n",
        "    # ========================================\n",
        "    #               Training\n",
        "    # ========================================\n",
        "    \n",
        "    # Perform one full pass over the training set.\n",
        "\n",
        "    print(\"\")\n",
        "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
        "    print('Training...')\n",
        "\n",
        "\n",
        "    t0 = time.time()\n",
        "    # Reset the total loss for this epoch.\n",
        "    total_train_loss = 0\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    # For each batch of training data...\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "\n",
        "        # Progress update every 40 batches.\n",
        "        if step % 40 == 0 and not step == 0:\n",
        "            # Calculate elapsed time in minutes.\n",
        "            elapsed = format_time(time.time() - t0)\n",
        "            # Report progress.\n",
        "            print('  Batch {} of {}. Elapse: {:}'.format(step, len(train_dataloader), elapsed))\n",
        "\n",
        "        # Unpack this training batch from our dataloader. \n",
        "        #\n",
        "        # As we unpack the batch, we'll also copy each tensor to the GPU using the \n",
        "        # `to` method.\n",
        "        #\n",
        "        # `batch` contains three pytorch tensors:\n",
        "        #   [0]: input ids \n",
        "        #   [1]: attention masks\n",
        "        #   [2]: token type ids\n",
        "        #   [3]: labels \n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_token_type_ids = batch[2].to(device)\n",
        "        b_labels = batch[3].to(device)\n",
        "\n",
        "        model.zero_grad()        \n",
        "\n",
        "        loss, logits = model(b_input_ids, \n",
        "                             token_type_ids=b_token_type_ids, \n",
        "                             attention_mask=b_input_mask, \n",
        "                             labels=b_labels)\n",
        "\n",
        "        total_train_loss += loss.item()\n",
        "\n",
        "        # Perform a backward pass to calculate the gradients.\n",
        "        loss.backward()\n",
        "\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\n",
        "\n",
        "        optimizer.step()\n",
        "\n",
        "        # Update the learning rate.\n",
        "        scheduler.step()\n",
        "\n",
        "    # Calculate the average loss over all of the batches.\n",
        "    avg_train_loss = total_train_loss / len(train_dataloader)            \n",
        "    training_time = format_time(time.time() - t0)\n",
        "\n",
        "    \n",
        "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "    print(\"  Training epoch took: {:}\".format(training_time))    \n",
        "    # ========================================\n",
        "    #               Validation\n",
        "    # ========================================\n",
        "    # After the completion of each training epoch, measure our performance on\n",
        "    # our validation set.\n",
        "\n",
        "    print(\"Running Validation...\")\n",
        "    t0 = time.time()\n",
        "    \n",
        "    # Put the model in evaluation mode--the dropout layers behave differently\n",
        "    # during evaluation.\n",
        "    # Tracking variables \n",
        "    total_eval_accuracy = 0\n",
        "    total_eval_loss = 0\n",
        "    nb_eval_steps = 0\n",
        "    f1 = 0\n",
        "\n",
        "    model.eval()\n",
        "    # Evaluate data for one epoch\n",
        "    for batch in dev_dataloader:\n",
        "        \n",
        "        # Unpack this training batch from our dataloader. \n",
        "        #\n",
        "        # As we unpack the batch, we'll also copy each tensor to the GPU using \n",
        "        # the `to` method.\n",
        "        #\n",
        "        # `batch` contains three pytorch tensors:\n",
        "        #   [0]: input ids \n",
        "        #   [1]: attention masks\n",
        "        #   [2]: token type ids\n",
        "        #   [3]: labels \n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_token_type_ids = batch[2].to(device)\n",
        "        b_labels = batch[3].to(device)\n",
        "        \n",
        "        with torch.no_grad():        \n",
        "\n",
        "            (loss, logits) = model(b_input_ids, \n",
        "                                   token_type_ids=b_token_type_ids, \n",
        "                                   attention_mask=b_input_mask,\n",
        "                                   labels=b_labels)\n",
        "            \n",
        "        # Accumulate the validation loss.\n",
        "        total_eval_loss += loss.item()\n",
        "\n",
        "        # Move logits and labels to CPU\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "        # Calculate the accuracy for this batch of test sentences, and\n",
        "        # accumulate it over all batches.\n",
        "        total_eval_accuracy += flat_accuracy(logits, label_ids)\n",
        "        f1 += f1_score(label_ids, np.argmax(logits, axis=1).flatten(), average='weighted')\n",
        "        \n",
        "\n",
        "    # Report the final accuracy for this validation run.\n",
        "    avg_val_accuracy = total_eval_accuracy / len(dev_dataloader)\n",
        "    avg_f1_score = f1 / len(dev_dataloader)\n",
        "    print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n",
        "    print(\"  F1-Score: {0:.2f}\".format(avg_f1_score))\n",
        "\n",
        "    # Calculate the average loss over all of the batches.\n",
        "    avg_val_loss = total_eval_loss / len(dev_dataloader)\n",
        "    \n",
        "    print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
        "\n",
        "    # Record all statistics from this epoch.\n",
        "    training_stats.append(\n",
        "        {\n",
        "            'epoch': epoch_i + 1,\n",
        "            'Training Loss': avg_train_loss,\n",
        "            'Valid. Loss': avg_val_loss,\n",
        "            'Valid. Accur.': avg_val_accuracy,\n",
        "\n",
        "        }\n",
        "    )\n",
        "\n",
        "print(\"\")\n",
        "print(\"Training complete!\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 / 4 ========\n",
            "Training...\n",
            "  Batch 40 of 2105. Elapse: 0:00:05\n",
            "  Batch 80 of 2105. Elapse: 0:00:10\n",
            "  Batch 120 of 2105. Elapse: 0:00:14\n",
            "  Batch 160 of 2105. Elapse: 0:00:19\n",
            "  Batch 200 of 2105. Elapse: 0:00:24\n",
            "  Batch 240 of 2105. Elapse: 0:00:28\n",
            "  Batch 280 of 2105. Elapse: 0:00:33\n",
            "  Batch 320 of 2105. Elapse: 0:00:38\n",
            "  Batch 360 of 2105. Elapse: 0:00:42\n",
            "  Batch 400 of 2105. Elapse: 0:00:47\n",
            "  Batch 440 of 2105. Elapse: 0:00:51\n",
            "  Batch 480 of 2105. Elapse: 0:00:56\n",
            "  Batch 520 of 2105. Elapse: 0:01:01\n",
            "  Batch 560 of 2105. Elapse: 0:01:05\n",
            "  Batch 600 of 2105. Elapse: 0:01:10\n",
            "  Batch 640 of 2105. Elapse: 0:01:15\n",
            "  Batch 680 of 2105. Elapse: 0:01:19\n",
            "  Batch 720 of 2105. Elapse: 0:01:24\n",
            "  Batch 760 of 2105. Elapse: 0:01:29\n",
            "  Batch 800 of 2105. Elapse: 0:01:33\n",
            "  Batch 840 of 2105. Elapse: 0:01:38\n",
            "  Batch 880 of 2105. Elapse: 0:01:43\n",
            "  Batch 920 of 2105. Elapse: 0:01:47\n",
            "  Batch 960 of 2105. Elapse: 0:01:52\n",
            "  Batch 1000 of 2105. Elapse: 0:01:57\n",
            "  Batch 1040 of 2105. Elapse: 0:02:01\n",
            "  Batch 1080 of 2105. Elapse: 0:02:06\n",
            "  Batch 1120 of 2105. Elapse: 0:02:11\n",
            "  Batch 1160 of 2105. Elapse: 0:02:15\n",
            "  Batch 1200 of 2105. Elapse: 0:02:20\n",
            "  Batch 1240 of 2105. Elapse: 0:02:25\n",
            "  Batch 1280 of 2105. Elapse: 0:02:29\n",
            "  Batch 1320 of 2105. Elapse: 0:02:34\n",
            "  Batch 1360 of 2105. Elapse: 0:02:39\n",
            "  Batch 1400 of 2105. Elapse: 0:02:43\n",
            "  Batch 1440 of 2105. Elapse: 0:02:48\n",
            "  Batch 1480 of 2105. Elapse: 0:02:53\n",
            "  Batch 1520 of 2105. Elapse: 0:02:58\n",
            "  Batch 1560 of 2105. Elapse: 0:03:02\n",
            "  Batch 1600 of 2105. Elapse: 0:03:07\n",
            "  Batch 1640 of 2105. Elapse: 0:03:12\n",
            "  Batch 1680 of 2105. Elapse: 0:03:16\n",
            "  Batch 1720 of 2105. Elapse: 0:03:21\n",
            "  Batch 1760 of 2105. Elapse: 0:03:26\n",
            "  Batch 1800 of 2105. Elapse: 0:03:30\n",
            "  Batch 1840 of 2105. Elapse: 0:03:35\n",
            "  Batch 1880 of 2105. Elapse: 0:03:40\n",
            "  Batch 1920 of 2105. Elapse: 0:03:45\n",
            "  Batch 1960 of 2105. Elapse: 0:03:49\n",
            "  Batch 2000 of 2105. Elapse: 0:03:54\n",
            "  Batch 2040 of 2105. Elapse: 0:03:59\n",
            "  Batch 2080 of 2105. Elapse: 0:04:03\n",
            "  Average training loss: 0.26\n",
            "  Training epoch took: 0:04:06\n",
            "Running Validation...\n",
            "  Accuracy: 0.91\n",
            "  F1-Score: 0.91\n",
            "  Validation Loss: 0.28\n",
            "\n",
            "======== Epoch 2 / 4 ========\n",
            "Training...\n",
            "  Batch 40 of 2105. Elapse: 0:00:05\n",
            "  Batch 80 of 2105. Elapse: 0:00:09\n",
            "  Batch 120 of 2105. Elapse: 0:00:14\n",
            "  Batch 160 of 2105. Elapse: 0:00:19\n",
            "  Batch 200 of 2105. Elapse: 0:00:23\n",
            "  Batch 240 of 2105. Elapse: 0:00:28\n",
            "  Batch 280 of 2105. Elapse: 0:00:33\n",
            "  Batch 320 of 2105. Elapse: 0:00:38\n",
            "  Batch 360 of 2105. Elapse: 0:00:42\n",
            "  Batch 400 of 2105. Elapse: 0:00:47\n",
            "  Batch 440 of 2105. Elapse: 0:00:52\n",
            "  Batch 480 of 2105. Elapse: 0:00:56\n",
            "  Batch 520 of 2105. Elapse: 0:01:01\n",
            "  Batch 560 of 2105. Elapse: 0:01:06\n",
            "  Batch 600 of 2105. Elapse: 0:01:10\n",
            "  Batch 640 of 2105. Elapse: 0:01:15\n",
            "  Batch 680 of 2105. Elapse: 0:01:20\n",
            "  Batch 720 of 2105. Elapse: 0:01:25\n",
            "  Batch 760 of 2105. Elapse: 0:01:29\n",
            "  Batch 800 of 2105. Elapse: 0:01:34\n",
            "  Batch 840 of 2105. Elapse: 0:01:39\n",
            "  Batch 880 of 2105. Elapse: 0:01:43\n",
            "  Batch 920 of 2105. Elapse: 0:01:48\n",
            "  Batch 960 of 2105. Elapse: 0:01:53\n",
            "  Batch 1000 of 2105. Elapse: 0:01:57\n",
            "  Batch 1040 of 2105. Elapse: 0:02:02\n",
            "  Batch 1080 of 2105. Elapse: 0:02:07\n",
            "  Batch 1120 of 2105. Elapse: 0:02:12\n",
            "  Batch 1160 of 2105. Elapse: 0:02:16\n",
            "  Batch 1200 of 2105. Elapse: 0:02:21\n",
            "  Batch 1240 of 2105. Elapse: 0:02:26\n",
            "  Batch 1280 of 2105. Elapse: 0:02:30\n",
            "  Batch 1320 of 2105. Elapse: 0:02:35\n",
            "  Batch 1360 of 2105. Elapse: 0:02:40\n",
            "  Batch 1400 of 2105. Elapse: 0:02:44\n",
            "  Batch 1440 of 2105. Elapse: 0:02:49\n",
            "  Batch 1480 of 2105. Elapse: 0:02:54\n",
            "  Batch 1520 of 2105. Elapse: 0:02:58\n",
            "  Batch 1560 of 2105. Elapse: 0:03:03\n",
            "  Batch 1600 of 2105. Elapse: 0:03:08\n",
            "  Batch 1640 of 2105. Elapse: 0:03:12\n",
            "  Batch 1680 of 2105. Elapse: 0:03:17\n",
            "  Batch 1720 of 2105. Elapse: 0:03:22\n",
            "  Batch 1760 of 2105. Elapse: 0:03:27\n",
            "  Batch 1800 of 2105. Elapse: 0:03:31\n",
            "  Batch 1840 of 2105. Elapse: 0:03:36\n",
            "  Batch 1880 of 2105. Elapse: 0:03:41\n",
            "  Batch 1920 of 2105. Elapse: 0:03:45\n",
            "  Batch 1960 of 2105. Elapse: 0:03:50\n",
            "  Batch 2000 of 2105. Elapse: 0:03:55\n",
            "  Batch 2040 of 2105. Elapse: 0:03:59\n",
            "  Batch 2080 of 2105. Elapse: 0:04:04\n",
            "  Average training loss: 0.15\n",
            "  Training epoch took: 0:04:07\n",
            "Running Validation...\n",
            "  Accuracy: 0.93\n",
            "  F1-Score: 0.93\n",
            "  Validation Loss: 0.24\n",
            "\n",
            "======== Epoch 3 / 4 ========\n",
            "Training...\n",
            "  Batch 40 of 2105. Elapse: 0:00:05\n",
            "  Batch 80 of 2105. Elapse: 0:00:09\n",
            "  Batch 120 of 2105. Elapse: 0:00:14\n",
            "  Batch 160 of 2105. Elapse: 0:00:19\n",
            "  Batch 200 of 2105. Elapse: 0:00:23\n",
            "  Batch 240 of 2105. Elapse: 0:00:28\n",
            "  Batch 280 of 2105. Elapse: 0:00:33\n",
            "  Batch 320 of 2105. Elapse: 0:00:38\n",
            "  Batch 360 of 2105. Elapse: 0:00:42\n",
            "  Batch 400 of 2105. Elapse: 0:00:47\n",
            "  Batch 440 of 2105. Elapse: 0:00:52\n",
            "  Batch 480 of 2105. Elapse: 0:00:56\n",
            "  Batch 520 of 2105. Elapse: 0:01:01\n",
            "  Batch 560 of 2105. Elapse: 0:01:06\n",
            "  Batch 600 of 2105. Elapse: 0:01:10\n",
            "  Batch 640 of 2105. Elapse: 0:01:15\n",
            "  Batch 680 of 2105. Elapse: 0:01:20\n",
            "  Batch 720 of 2105. Elapse: 0:01:24\n",
            "  Batch 760 of 2105. Elapse: 0:01:29\n",
            "  Batch 800 of 2105. Elapse: 0:01:34\n",
            "  Batch 840 of 2105. Elapse: 0:01:38\n",
            "  Batch 880 of 2105. Elapse: 0:01:43\n",
            "  Batch 920 of 2105. Elapse: 0:01:48\n",
            "  Batch 960 of 2105. Elapse: 0:01:53\n",
            "  Batch 1000 of 2105. Elapse: 0:01:57\n",
            "  Batch 1040 of 2105. Elapse: 0:02:02\n",
            "  Batch 1080 of 2105. Elapse: 0:02:07\n",
            "  Batch 1120 of 2105. Elapse: 0:02:11\n",
            "  Batch 1160 of 2105. Elapse: 0:02:16\n",
            "  Batch 1200 of 2105. Elapse: 0:02:21\n",
            "  Batch 1240 of 2105. Elapse: 0:02:25\n",
            "  Batch 1280 of 2105. Elapse: 0:02:30\n",
            "  Batch 1320 of 2105. Elapse: 0:02:35\n",
            "  Batch 1360 of 2105. Elapse: 0:02:39\n",
            "  Batch 1400 of 2105. Elapse: 0:02:44\n",
            "  Batch 1440 of 2105. Elapse: 0:02:49\n",
            "  Batch 1480 of 2105. Elapse: 0:02:54\n",
            "  Batch 1520 of 2105. Elapse: 0:02:58\n",
            "  Batch 1560 of 2105. Elapse: 0:03:03\n",
            "  Batch 1600 of 2105. Elapse: 0:03:08\n",
            "  Batch 1640 of 2105. Elapse: 0:03:12\n",
            "  Batch 1680 of 2105. Elapse: 0:03:17\n",
            "  Batch 1720 of 2105. Elapse: 0:03:22\n",
            "  Batch 1760 of 2105. Elapse: 0:03:27\n",
            "  Batch 1800 of 2105. Elapse: 0:03:31\n",
            "  Batch 1840 of 2105. Elapse: 0:03:36\n",
            "  Batch 1880 of 2105. Elapse: 0:03:41\n",
            "  Batch 1920 of 2105. Elapse: 0:03:45\n",
            "  Batch 1960 of 2105. Elapse: 0:03:50\n",
            "  Batch 2000 of 2105. Elapse: 0:03:55\n",
            "  Batch 2040 of 2105. Elapse: 0:03:59\n",
            "  Batch 2080 of 2105. Elapse: 0:04:04\n",
            "  Average training loss: 0.11\n",
            "  Training epoch took: 0:04:07\n",
            "Running Validation...\n",
            "  Accuracy: 0.92\n",
            "  F1-Score: 0.92\n",
            "  Validation Loss: 0.31\n",
            "\n",
            "======== Epoch 4 / 4 ========\n",
            "Training...\n",
            "  Batch 40 of 2105. Elapse: 0:00:05\n",
            "  Batch 80 of 2105. Elapse: 0:00:09\n",
            "  Batch 120 of 2105. Elapse: 0:00:14\n",
            "  Batch 160 of 2105. Elapse: 0:00:19\n",
            "  Batch 200 of 2105. Elapse: 0:00:23\n",
            "  Batch 240 of 2105. Elapse: 0:00:28\n",
            "  Batch 280 of 2105. Elapse: 0:00:33\n",
            "  Batch 320 of 2105. Elapse: 0:00:38\n",
            "  Batch 360 of 2105. Elapse: 0:00:42\n",
            "  Batch 400 of 2105. Elapse: 0:00:47\n",
            "  Batch 440 of 2105. Elapse: 0:00:52\n",
            "  Batch 480 of 2105. Elapse: 0:00:56\n",
            "  Batch 520 of 2105. Elapse: 0:01:01\n",
            "  Batch 560 of 2105. Elapse: 0:01:06\n",
            "  Batch 600 of 2105. Elapse: 0:01:10\n",
            "  Batch 640 of 2105. Elapse: 0:01:15\n",
            "  Batch 680 of 2105. Elapse: 0:01:20\n",
            "  Batch 720 of 2105. Elapse: 0:01:25\n",
            "  Batch 760 of 2105. Elapse: 0:01:29\n",
            "  Batch 800 of 2105. Elapse: 0:01:34\n",
            "  Batch 840 of 2105. Elapse: 0:01:39\n",
            "  Batch 880 of 2105. Elapse: 0:01:43\n",
            "  Batch 920 of 2105. Elapse: 0:01:48\n",
            "  Batch 960 of 2105. Elapse: 0:01:53\n",
            "  Batch 1000 of 2105. Elapse: 0:01:57\n",
            "  Batch 1040 of 2105. Elapse: 0:02:02\n",
            "  Batch 1080 of 2105. Elapse: 0:02:07\n",
            "  Batch 1120 of 2105. Elapse: 0:02:11\n",
            "  Batch 1160 of 2105. Elapse: 0:02:16\n",
            "  Batch 1200 of 2105. Elapse: 0:02:21\n",
            "  Batch 1240 of 2105. Elapse: 0:02:26\n",
            "  Batch 1280 of 2105. Elapse: 0:02:30\n",
            "  Batch 1320 of 2105. Elapse: 0:02:35\n",
            "  Batch 1360 of 2105. Elapse: 0:02:40\n",
            "  Batch 1400 of 2105. Elapse: 0:02:44\n",
            "  Batch 1440 of 2105. Elapse: 0:02:49\n",
            "  Batch 1480 of 2105. Elapse: 0:02:54\n",
            "  Batch 1520 of 2105. Elapse: 0:02:58\n",
            "  Batch 1560 of 2105. Elapse: 0:03:03\n",
            "  Batch 1600 of 2105. Elapse: 0:03:08\n",
            "  Batch 1640 of 2105. Elapse: 0:03:12\n",
            "  Batch 1680 of 2105. Elapse: 0:03:17\n",
            "  Batch 1720 of 2105. Elapse: 0:03:22\n",
            "  Batch 1760 of 2105. Elapse: 0:03:26\n",
            "  Batch 1800 of 2105. Elapse: 0:03:31\n",
            "  Batch 1840 of 2105. Elapse: 0:03:36\n",
            "  Batch 1880 of 2105. Elapse: 0:03:40\n",
            "  Batch 1920 of 2105. Elapse: 0:03:45\n",
            "  Batch 1960 of 2105. Elapse: 0:03:50\n",
            "  Batch 2000 of 2105. Elapse: 0:03:55\n",
            "  Batch 2040 of 2105. Elapse: 0:03:59\n",
            "  Batch 2080 of 2105. Elapse: 0:04:04\n",
            "  Average training loss: 0.09\n",
            "  Training epoch took: 0:04:07\n",
            "Running Validation...\n",
            "  Accuracy: 0.92\n",
            "  F1-Score: 0.92\n",
            "  Validation Loss: 0.33\n",
            "\n",
            "Training complete!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XA9PXDhTdRh7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 103
        },
        "outputId": "a69d1c52-da12-48f5-8ad2-ad5d6ceb3748"
      },
      "source": [
        "import os\n",
        "os.makedirs(os.getcwd(), exist_ok=True)\n",
        "print(\"Saving model to {}\".format(os.getcwd()))\n",
        "\n",
        "# Save trained model, configuration and tokenizer\n",
        "model_to_save = model.module if hasattr(model, 'model') else model\n",
        "model_to_save.save_pretrained(os.getcwd())\n",
        "tokenizer.save_pretrained(os.getcwd())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saving model to /content\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('/content/vocab.json',\n",
              " '/content/merges.txt',\n",
              " '/content/special_tokens_map.json',\n",
              " '/content/added_tokens.json')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KXVbeuRkqnqf"
      },
      "source": [
        "## Test Set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DkXzP-26qrvQ"
      },
      "source": [
        "from functools import partial\n",
        "testing = process(test, 32, 'test')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Io3R6mPkqryv"
      },
      "source": [
        "test_preds = do_prediction(model, testing, device)\n",
        "test['preds'] = test_preds"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cUQBN6csquV0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 202
        },
        "outputId": "0d96d576-b3d6-47c3-8081-e1eb11b4cdbd"
      },
      "source": [
        "test.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>sentence</th>\n",
              "      <th>preds</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>uneasy mishmash of styles and genres .</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>this film 's relationship to actual tension is...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>by the end of no such thing the audience , lik...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>director rob marshall went out gunning to make...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>lathan and diggs have considerable personal ch...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   index                                           sentence  preds\n",
              "0      0             uneasy mishmash of styles and genres .      0\n",
              "1      1  this film 's relationship to actual tension is...      1\n",
              "2      2  by the end of no such thing the audience , lik...      1\n",
              "3      3  director rob marshall went out gunning to make...      1\n",
              "4      4  lathan and diggs have considerable personal ch...      1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8tJNV5bDqyba",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "ec459abb-1b21-46cb-c314-51f18927ddde"
      },
      "source": [
        "test.preds.value_counts(normalize=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    0.529929\n",
              "0    0.470071\n",
              "Name: preds, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    }
  ]
}